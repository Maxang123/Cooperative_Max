import os
import cv2
import numpy as np
import pickle
import insightface
from sklearn.metrics.pairwise import cosine_similarity
from insightface.app import FaceAnalysis
import mediapipe as mp
import time

# ============================
# 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
# ============================

# Initialize InsightFace FaceAnalysis (ArcFace)
app = FaceAnalysis()
app.prepare(ctx_id=0, det_size=(640, 640))  # ‡πÉ‡∏ä‡πâ GPU: ctx_id=0, CPU: ctx_id=-1

# Initialize Mediapipe Face Mesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏≤‡∏î landmark (optional)
mp_drawing = mp.solutions.drawing_utils

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°
triggered_behavior = None       # ‡πÄ‡∏ä‡πà‡∏ô "Blink 1" ‡∏´‡∏£‡∏∑‡∏≠ "Identity verification success"
behavior_timestamp = 0          # ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ñ‡∏π‡∏Å trigger

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤
blink_count = 0
blink_in_progress = False
verification_success = False
BLINK_THRESHOLD = 5  # threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤ (‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö)

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (head turn)
head_turn_behavior = None       # ‡πÄ‡∏ä‡πà‡∏ô "Turn Left" ‡∏´‡∏£‡∏∑‡∏≠ "Turn Right"
head_turn_timestamp = 0          # ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö

# ============================
# 2. ‡πÇ‡∏´‡∏•‡∏î Embeddings ‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Recognition
# ============================

def load_embeddings(filename):
    with open(filename, 'rb') as f:
        return pickle.load(f)

data = load_embeddings('embeddings_Best.pkl')

def extract_embeddings(image):
    faces = app.get(image)
    embeddings = []
    bboxes = []
    for face in faces:
        embeddings.append(face.normed_embedding)
        bboxes.append(face.bbox)  # ‡∏û‡∏¥‡∏Å‡∏±‡∏î bounding box
    return embeddings, bboxes

def match_face(new_face_embedding, data):
    if new_face_embedding.size == 0:
        return None, 0
    best_match = None
    best_score = -1
    new_face_embedding = np.array(new_face_embedding).reshape(1, -1)
    for person, embeddings in data.items():
        embeddings = embeddings.reshape(embeddings.shape[0], -1)
        scores = cosine_similarity(new_face_embedding, embeddings)
        max_score = max(scores[0])
        if max_score > best_score:
            best_match = person
            best_score = max_score
    return best_match, best_score

# ============================
# 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
# ============================

cap = cv2.VideoCapture(0)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î ROI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
roi_x1, roi_y1 = 150, 100
roi_x2, roi_y2 = 490, 380

while True:
    ret, frame = cap.read()
    if not ret:
        print("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ")
        break
    current_time = time.time()

    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö ROI ‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏°
    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 2)
    
    # --- Face Recognition ‡∏î‡πâ‡∏ß‡∏¢ InsightFace ---
    embeddings, bboxes = extract_embeddings(frame)
    if embeddings:
        for i, bbox in enumerate(bboxes):
            x1, y1, x2, y2 = map(int, bbox)
            face_center_x = (x1 + x2) // 2
            face_center_y = (y1 + y2) // 2
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏µ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ROI ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if not (roi_x1 <= face_center_x <= roi_x2 and roi_y1 <= face_center_y <= roi_y2):
                cv2.putText(frame, "Please align your face in the frame", (0, 70),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å ROI
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), (152, 0, 255), 2)
            result, score = match_face(embeddings[i], data)
            if result:
                cv2.putText(frame, f"{result} ({score:.2f})", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (152, 0, 255), 2)
            else:
                cv2.putText(frame, "No match found", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (152, 0, 255), 2)

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mediapipe
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_mesh_results = face_mesh.process(rgb_frame)

    if face_mesh_results.multi_face_landmarks:
        for face_landmarks in face_mesh_results.multi_face_landmarks:
            h, w, _ = frame.shape
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì bounding box ‡∏à‡∏≤‡∏Å landmark ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            x_coords = [landmark.x * w for landmark in face_landmarks.landmark]
            y_coords = [landmark.y * h for landmark in face_landmarks.landmark]
            min_x, max_x = int(min(x_coords)), int(max(x_coords))
            min_y, max_y = int(min(y_coords)), int(max(y_coords))
            face_box_width = max_x - min_x
            face_box_height = max_y - min_y
            face_center_x = (min_x + max_x) // 2
            face_center_y = (min_y + max_y) // 2

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏û‡∏≠‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ROI (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á)
            if face_box_width < 150 or face_box_height < 150 or not (roi_x1 <= face_center_x <= roi_x2 and roi_y1 <= face_center_y <= roi_y2):
                cv2.putText(frame, "Please move closer and align face", (0,30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                continue
            
            # Optional: ‡∏ß‡∏≤‡∏î bounding box ‡∏à‡∏≤‡∏Å landmarks
            # cv2.rectangle(frame, (min_x, min_y), (max_x, max_y), (0, 255, 255), 2)

            # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ö‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Mediapipe Face Mesh ---

            """
            ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏¥‡πâ‡∏°: ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ landmark ‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏°‡∏∏‡∏°‡∏ã‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ç‡∏ß‡∏≤‡∏õ‡∏≤‡∏Å (landmark 61 ‡πÅ‡∏•‡∏∞ 291) 
            ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏õ‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏Ç‡πâ‡∏≤‡∏á (landmark 234 ‡πÅ‡∏•‡∏∞ 454) 
            ‡∏´‡∏≤‡∏Å‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô 0.5 ‡∏à‡∏∞‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏≠‡∏¢‡∏¢‡∏¥‡πâ‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‚ÄúSmile (¬Ø‚ñΩ¬Ø)‚Äù  
            """
            left_mouth = face_landmarks.landmark[61]
            right_mouth = face_landmarks.landmark[291]
            pt_left_mouth = np.array([left_mouth.x * w, left_mouth.y * h])
            pt_right_mouth = np.array([right_mouth.x * w, right_mouth.y * h])
            mouth_width = np.linalg.norm(pt_left_mouth - pt_right_mouth)
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ landmark 234 (‡πÅ‡∏Å‡πâ‡∏°‡∏ã‡πâ‡∏≤‡∏¢) ‡πÅ‡∏•‡∏∞ 454 (‡πÅ‡∏Å‡πâ‡∏°‡∏Ç‡∏ß‡∏≤)
            left_face = face_landmarks.landmark[234]
            right_face = face_landmarks.landmark[454]
            pt_left_face = np.array([left_face.x * w, left_face.y * h])
            pt_right_face = np.array([right_face.x * w, right_face.y * h])
            face_width = np.linalg.norm(pt_left_face - pt_right_face)
            if face_width > 0:
                smile_ratio = mouth_width / face_width
                if smile_ratio > 0.5:
                    triggered_behavior = "Smile (¬Ø‚ñΩ¬Ø)"
                    behavior_timestamp = current_time

            # **‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤ (Blink) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô**
            """
            ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô): ‡πÉ‡∏ä‡πâ landmark ‡∏Ç‡∏≠‡∏á‡∏î‡∏ß‡∏á‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢ (top: landmark 159, bottom: landmark 145) 
            ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î ‡∏´‡∏≤‡∏Å‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ BLINK_THRESHOLD ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö blink_count ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤‡∏Ñ‡∏£‡∏ö 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á 
            ‡∏à‡∏∞‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‚ÄúIdentity verification success (O_o)‚Äù 
            """
            if not verification_success:
                left_eye_top = face_landmarks.landmark[159]
                left_eye_bottom = face_landmarks.landmark[145]
                pt_top = np.array([left_eye_top.x * w, left_eye_top.y * h])
                pt_bottom = np.array([left_eye_bottom.x * w, left_eye_bottom.y * h])
                eye_distance = np.linalg.norm(pt_top - pt_bottom)
                
                if eye_distance < BLINK_THRESHOLD:
                    if not blink_in_progress:
                        blink_in_progress = True
                        blink_count += 1
                        triggered_behavior = f"Blink {blink_count}! (>_<)"
                        behavior_timestamp = current_time
                        if blink_count >= 3:
                            verification_success = True
                            triggered_behavior = "Identity verification success (O_o)"
                            behavior_timestamp = current_time
                else:
                    blink_in_progress = False

            # **‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ã‡πâ‡∏≤‡∏¢/‡∏Ç‡∏ß‡∏≤ (Head Turn)**
            """
            ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤: ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ landmark ‡∏Ç‡∏≠‡∏á‡∏à‡∏°‡∏π‡∏Å (landmark 1) ‡πÅ‡∏•‡∏∞‡∏î‡∏ß‡∏á‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤ (landmark 33 ‡πÅ‡∏•‡∏∞ 263) 
            ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô‡πÅ‡∏Å‡∏ô x ‡∏ñ‡πâ‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏±‡∏ô‡πÑ‡∏õ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (15 ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•) 
            ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‚ÄúTurn Right-->‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚ÄúTurn Left<--‚Äù 
            """
            nose = face_landmarks.landmark[1]
            left_eye = face_landmarks.landmark[33]
            right_eye = face_landmarks.landmark[263]
            nose_x = nose.x * w
            left_eye_x = left_eye.x * w
            right_eye_x = right_eye.x * w
            eyes_mid_x = (left_eye_x + right_eye_x) / 2
            if (eyes_mid_x - nose_x) > 15:
                head_turn_behavior = "Turn Right-->"
                head_turn_timestamp = current_time
            elif (nose_x - eyes_mid_x) > 15:
                head_turn_behavior = "Turn Left<--"
                head_turn_timestamp = current_time

            # ‡∏ß‡∏≤‡∏î landmark ‡∏ö‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (optional)
            # mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION,
            #                           landmark_drawing_spec=None,
            #                           connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=1, circle_radius=1))
    else:
        # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏° ‡πÉ‡∏´‡πâ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Ñ‡πà‡∏≤‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°
        blink_count = 0
        blink_in_progress = False
        verification_success = False
        triggered_behavior = None
        head_turn_behavior = None
        behavior_timestamp = 0
        head_turn_timestamp = 0

    # --- ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏° ---
    if not verification_success:
        cv2.putText(frame, "Please blink 3 times slowly", (0, 450),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
    if triggered_behavior is not None and (current_time - behavior_timestamp) < 1:
        cv2.putText(frame, triggered_behavior, (0, 400), cv2.FONT_HERSHEY_SIMPLEX,
                    1, (0, 0, 0), 3)
    if head_turn_behavior is not None and (current_time - head_turn_timestamp) < 1:
        cv2.putText(frame, head_turn_behavior, (0, 90), cv2.FONT_HERSHEY_SIMPLEX,
                    1, (0, 0, 0), 3)

    cv2.imshow("Face Recognition with Blink Verificationüòé", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
